## Kaggle 经验小结
  By Di Chen - chenditc@gmail.com
  
- - - - 

### Kaggle是个数据挖掘比赛
许多人认为Kaggle是个机器学习比赛，从而恶补了许多机器学习的算法，希望借此大展身手。但是在我看来，Kaggle更像是个数据挖掘比赛，重要的不是你用了多么高级的算法，而是你最终的成绩如何。

在许多冠军的代码里，大部分都在做数据的预处理和特征提取，机器学习只是把所有特征整合的一个步骤，大部分的时间精力则花在了理解数据，预处理数据，提取特征，消除噪声等等。

### 特征工程 (Feature Engineering)
如果要说一个在Kaggle比赛里最重要的技能，我一定会说是特征工程。特征工程指的是在原始数据之中提取，构造，选择数据特征的过程。有句话是：“数据和特征工程决定了你能到达的上限，机器学习模型决定了你能多么逼近这个上限”。

在Kaggle以及一些数据科学的比赛中，特征工程的方法根据原始数据的不同，也有许多不同的方法。比如从销售量中提取出销售量的增长率，从投保人资料里提取出的收入/支出比率，这些都能为机器学习的算法提供额外的信息。并且根据使用的机器学习模型不同，使用的准确率计算方法不同，数据量不同，都对特征工程的方法选取有很大影响。

选择好的特征提取方法，不光需要数据科学的知识，更需要对数据以及要解决的问题的理解，这些知识在大部分的机器学习资料中都没有提及，但是在工业界的数据科学工作中，都是必不可缺的。数据科学的比赛就是一个很好的学习平台。

### 代码测试
在数据科学的比赛中，大部分人都会写一些脚本来预处理数据，不过许多人都忽视了测试和验证的步骤。这就导致了很多算法看似表现不佳，实则是代码本身存在着bug。比如用label indexing将地址转化成数字label的过程中，由于地址的预处理不恰当，地址前后的空格没有去掉，相似的地址就被抓化成了不同的label，导致机器学习模型表现不佳。

为了保证代码的正确性，以及合理性，最简单的方法就是将每一步处理之后的数据显示出来并验证一下，比如计算最大最小值，看看是不是在合理的区间内。

### 项目时间安排

  1. 代码实现 - 20%
  2. 分析结果 - 20%
  3. 阅读相关材料 - 20%
  4. 阅读冠军解法、代码 - 20%
  5. 实现冠军解法、代码 - 20%

对于我个人来说，步骤1，2，3是不断交替的。在实现了一个想法之后，分析这个模型的结果，找出不足之处或者可提高的地方，然后阅读相关的材料补充知识。在获取了新的知识之后，重新实现自己的想法。在1，2，3交替的过程中，不断完善自己的模型并且学习新的知识。

步骤4，5主要是学习他人的算法。在一个数据科学的项目中，如果是为了提升自己的数据科学技能和水平，阅读他人的代码并且重新实现一遍是非常重要的，这个可以保证你下一次遇到类似问题的时候，能够独立找出解决方案。我认为这个过程值得花至少40%的时间。
  
### Kaggle论坛
Kaggle比赛里有很多很好的资源，论坛（Forum）就是其中一个。在Kaggle论坛上，参赛者经常会分享他们的经验，困难，以及一些代码。多逛逛Kaggle的论坛不光可以学习别人好的算法，也可以启发自己的思路。在每次比赛之后，取得好成绩的参赛者经常会把自己的方法发到论坛上，我们就可以借此学习新的特征工程跟机器学习的算法了。

### 交叉验证 (Cross Valdiataion)
Kaggle提供了一个很棒的Leaderboard功能，就是当你提交一个答案时，将一部分的test data的准确率计算出来，并作为你排名的分数。这样你就可以看到你在所有参赛者中是什么排名。

这个功能虽然很棒，但是许多人将其作为评价自己算法的标准，我认为这是非常不妥的。如果一个参赛者用leaderboard作为评价自己算法的标准，这就相当于用作validation data set，并用来调整参数。这样就会使算法overfit test data的一部分。在最终评价的时候，加入了另一部分test data的准确率，有可能分数会降低许多。

我认为交叉验证 (Cross Valdiataion) 是一个比较合适的替代方法。在实际工业界的工作中，也不会有leaderboard这样的东西来评价算法，交叉验证就是将traning data分成N份，每次用N-1份用于训练，用剩下的一份来测试准确率，这样就不会overfit某一部分特定的数据了。

### 最常用的模型
在Kaggle的比赛里，没有一个模型是适用于所有比赛的，但是有一些模型在大部分的情况下表现都非常好。
1. Boosted Decision Tree，以 https://github.com/dmlc/xgboost 为代表，大部分比赛里都可以作为不错的baseline使用。
2. Deep neural network。由于neural network本身就有特征提取的效果，在一些比赛中，能为最后的model ensemble提供一个供选择的模型。由于training的时间跟neural network的大小，还有数据量的大小都有关，如果没有GPU支持的话，很多都需要training很久的时间。
3. Random Forest Tree. 跟Boosted Decision Tree类似，属于跑得快，效果好，还能有feature selection功能的模型。也是个不错的baseline。
